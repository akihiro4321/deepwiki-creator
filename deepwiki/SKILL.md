---
name: deepwiki
description: コードベースを解析し、DeepWiki のような包括的なWikiドキュメントを自動生成するスキル。ユーザーが「Wikiを作成して」「コードベースをドキュメント化して」と依頼した場合に使用する。アーキテクチャ図（Mermaid）やコードスニペットを活用した詳細なドキュメントを生成する。
---

# DeepWiki - コードベース分析＆ドキュメント生成スキル

リポジトリを深く解析し、包括的なWikiドキュメント（DeepWiki）の自動生成を提供する。

> **品質目標**: 新しい開発者がこの Wiki を読むだけでプロジェクトの全体像を把握し、すぐに開発を開始できること。また、既存機能を拡張・修正する際に、関連モジュールの設計意図・依存関係・データフローをこの Wiki から把握して方針を検討できること。そのために、十分な網羅性・技術的深度・ソースコード参照密度を確保する。
>
> **言語ルール**: ページタイトル・ファイルパスなどは**英語**、本文は**日本語**で記述する。（詳細は [references/prompts.md](references/prompts.md) の「言語ルール」を参照）

**LLMへの指示**: 本ファイル (`SKILL.md`) は**実行手順 (アルゴリズム)** のみを示す。各ステップで要求される「出力フォーマット」「品質基準」「チェックリスト」などの詳細は、必ず以下のフェーズ対応リファレンスを参照しながら作業を進めること。

- **Phase 1 用**: [references/01-analysis-prompts.md](references/01-analysis-prompts.md)
- **Phase 2 用**: [references/02-structure-prompts.md](references/02-structure-prompts.md)
- **Phase 3 用**: [references/03-generation-prompts.md](references/03-generation-prompts.md)
- **Mermaid記述時（必須）**: [references/04-mermaid-rules.md](references/04-mermaid-rules.md)

---

## Phase 0: 開始前の確認（必須）

Phase 1 に進む前に、以下の2つのパスを確定する。**ユーザーのメッセージに含まれていない場合は必ず問い合わせること。** ターゲットディレクトリと出力ディレクトリが確定するまで Phase 1 に進んではいけない。

| 項目 | 説明 | 例 |
| :--- | :--- | :--- |
| **ターゲットディレクトリ** | 解析対象のコードベースのルートパス (`$TARGET_DIR`) | `/Users/username/projects/my-app` |
| **出力ディレクトリ** | Wiki ファイルの出力先パス (`$OUTPUT_DIR`) | デフォルト: `<ターゲット>/docs/wiki` |

---

## Phase 1: 構造分析

対象コードベースの全体像を把握する。README等のドキュメントが不十分でも、ソースコードから正確にアーキテクチャを理解する。

### Step 1a: メタデータ収集

1. コンテキスト取得スクリプトの実行:
   ```bash
   bash scripts/collect_structure.sh $TARGET_DIR
   ```
   （ディレクトリツリー、依存関係マップ、主要エクスポート・関数シグネチャの一覧などを取得）
2. 存在する主要ファイル（README, package.json等のパッケージ定義、ビルド設定、CI設定等）の優先的な読み取り。
3. 技術スタック、フレームワーク、主要な依存関係の特定。
4. エントリーポイント（`main.ts`, `index.ts` 等）の特定。
5. （モノレポの場合）各パッケージ間の依存関係の把握。

### Step 1b: ソースコード走査

> [!IMPORTANT]
> ファイル全体の深読みは Phase 3a で行うため、ここでは「浅く広く」各モジュールの責務・依存関係を把握し、**アーキテクチャ概要メモ**を作成することに集中する。

1. **importグラフの構築**: エントリーポイントから import されているモジュールを最大2階層辿り、依存の方向性や循環依存を把握する。
2. **主要ファイルのアウトライン取得**: `collect_structure.sh` で特定したファイルサイズ上位ファイルのアウトラインを取得し、複雑度（クラス数/メソッド数）を確認してページ分割の必要性を判断する。ファイル全体の精読はまだしない。
3. **アーキテクチャパターンの検出**: 主要なデザインパターン（Factory, Middleware, Repository 等）のキーワードをコード検索し、特定する。
4. **アーキテクチャ概要メモの作成**: 分析結果を整理する（フォーマット例については `prompts.md` を参照）。これが Phase 2 の入力となる。

---

## Phase 2: Wiki 構造設計

Step 1 の結果をもとに Wiki 構造を設計し、ユーザーの承認を得る。

### Step 2a: 構成の設計
`prompts.md` に記載された「規模ガイドライン」と「セクション構成テンプレート」に従い、Wikiのページ構造（id, title, filePaths, importance, relatedPages 等）を設計する。

### Step 2b: ユーザーへの提案と承認依頼（⚠️ 必須停止ポイント）
> [!CAUTION]
> **ここで完全に処理を一時停止 (STOP) すること。** 設計したWiki構造を提示し、**ユーザーから明示的な許可（「OK」「進めて」など）を得るまでは、絶対に Phase 3 (ページ作成) に進んではいけない。**

提案の際は、JSONではなく**Markdownの表形式**で提示すること。（提示フォーマットの厳密な例は `prompts.md` を参照）

### Step 2c: outline.json の出力
ユーザーから承認を得たら、Wiki出力ディレクトリ (`$OUTPUT_DIR/outline.json`) に進捗管理用のアウトラインをJSON形式で書き出す。
（JSONスキーマの詳細については `prompts.md` を参照。以降、ページ生成・検証完了ごとに `status` を `"pending"` から `"done"` に更新していくこと）

---

## Phase 3: ページ単位の分析・生成ループ

> [!CAUTION]
> **核心ルール: 全ページを一括生成 (バッチ処理) しない。必ず 1ページずつ「分析(3a) → 生成(3b) → 出力(3c) → 検証(3d)」のループを回すこと。** `importance: high` → `medium` → `low` の順に処理する。

### Step 3a: ソースコード分析（最重要フェーズ）
ページの `filePaths` に紐づくファイルを精読し、深い分析メモを作成する。
1. 対象ファイルを読み、参照した行範囲を必ず記録する。
2. 特に `importance: high` のページでは、**Deep Research (詳細調査ルール)** を実行し、呼び出し元・参照先の追跡を行う。
3. 抽出するコードスニペットの候補（5〜10個）などの**分析メモ**を作成する。（メモのフォーマットや要件については `prompts.md` を参照）

### Step 3b: ページ生成
分析メモを基に Markdown ページを生成する。（文字数、Mermaidダイヤグラムの制約、スニペット等の**厳格な品質基準・フォーマットルール**については `prompts.md` を完全に満たすこと）

### Step 3c: ファイル出力
生成したページを即座に `$OUTPUT_DIR` へファイルとして書き出す。次のページに進む前に必ず書き出すこと。

### Step 3d: 品質検証（バリデーションループ）
> **このステップを完了するまで、絶対に次のページの生成に着手してはならない。**

```bash
python3 scripts/validate_page.py <生成したファイル.md> --importance <high|medium|low>
```
1. **Grade B 以上 (75%+)**: 合格。初めて次のページへ進み、`outline.json` の `status` を `"done"` に更新する。
2. **Grade C (60-74%)**: 指摘項目 (`❌`, `⚠️`) を修正し再出力・再検証（最大2回まで）。
3. **Grade D 以下 (<60%)**: 分析不足。Step 3a に戻り、ソースコードを追加で読み直す。

---

## Phase 4: 結合・整形
（すべてのページの生成ループが完了した後に実行）

1. **インデックスページ (`index.md`) の作成**: プロジェクト名、説明、技術スタック、全体ダイアグラム、各ページへのリンク付き目次を作成する。
2. 全ページ間の相互リンク、ページ番号の一貫性を確認し、必要に応じて修正する。
3. 全体バリデーションの実行（必要に応じて）:
   ```bash
   python3 scripts/validate_page.py $OUTPUT_DIR --scale <small|medium|large>
   ```

## Phase 5: 完了報告
生成された Wiki の出力先パスと、主要なページのハイライトをユーザーに報告し、処理を終了する。

---

## GitHubリポジトリの場合（特殊ケース）

対象がGitHubリポジトリURLの場合：
1. `git clone --depth 1 <URL> /tmp/deepwiki-<repo-name>` で shallow clone
2. 上記の Phase 1〜4 を実行
3. 成果物を指定の出力先にコピー
4. クローンした一時ディレクトリを削除
